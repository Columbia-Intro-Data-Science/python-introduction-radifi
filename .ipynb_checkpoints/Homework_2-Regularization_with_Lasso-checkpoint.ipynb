{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "In this homework, you'll be required to load in a dataset which has about 500 features. By using\n",
    "Lasso ($L^1$) regression, we'll find the optimal constraint on the $L^1$ norm which gives us the best\n",
    "$R^2$. Then we'll plot the results.\n",
    "\n",
    "Recall we minimize the following on ** training data: $(x_i,y_i)$**\n",
    "\n",
    "$$\\min_{\\beta} \\frac{1}{N} \\sum_{i=1}^N (y_i - \\beta \\cdot x_i)^2 + \\lambda \\|\\beta \\|_{L^1}.$$\n",
    "\n",
    "\n",
    "Denoting $\\beta_{\\lambda}$ as the minimum of the above, we then choose $\\lambda$ to maximize $R^2$ on **testing data: $(x_j,y_j)$**\n",
    "\n",
    "$$ \\max_{\\lambda} 1 - \\frac{\\sum_{j} (y_j - \\beta_{\\lambda} \\cdot x_j)^2}{\\sum_j (y_j - \\bar y)^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load in hw2data.csv from ../data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Set y to be the y variable in the dataframe from a and X to be the remaining features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) As shown in the Booking.com example, using Lasso regression, find the regularization strength\n",
    "which optimizes the $R^2$. \n",
    "\n",
    "**Hint:** Take a range of alpha from `np.logspace(-8,-3,1000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Plot the training perforamnce versus the testing performance, and observe whree the test performance is\n",
    "maximized. I've written an outline of the code you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382732</td>\n",
       "      <td>-0.034242</td>\n",
       "      <td>1.096347</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.347451</td>\n",
       "      <td>-0.581268</td>\n",
       "      <td>-1.632635</td>\n",
       "      <td>-1.567768</td>\n",
       "      <td>-1.179158</td>\n",
       "      <td>1.301428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178793</td>\n",
       "      <td>-0.799422</td>\n",
       "      <td>0.240788</td>\n",
       "      <td>0.289121</td>\n",
       "      <td>0.412871</td>\n",
       "      <td>-0.198399</td>\n",
       "      <td>0.094192</td>\n",
       "      <td>-1.147611</td>\n",
       "      <td>-0.358114</td>\n",
       "      <td>-2.663126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555963</td>\n",
       "      <td>0.892474</td>\n",
       "      <td>-0.422315</td>\n",
       "      <td>0.104714</td>\n",
       "      <td>0.228053</td>\n",
       "      <td>0.201480</td>\n",
       "      <td>0.540774</td>\n",
       "      <td>-1.818078</td>\n",
       "      <td>-0.049324</td>\n",
       "      <td>0.239034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740137</td>\n",
       "      <td>-0.565498</td>\n",
       "      <td>0.476031</td>\n",
       "      <td>-2.158069</td>\n",
       "      <td>1.318551</td>\n",
       "      <td>-0.239297</td>\n",
       "      <td>-0.246794</td>\n",
       "      <td>-1.079343</td>\n",
       "      <td>-0.114226</td>\n",
       "      <td>10.399650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013240</td>\n",
       "      <td>-0.121945</td>\n",
       "      <td>0.339059</td>\n",
       "      <td>-0.589632</td>\n",
       "      <td>-0.895816</td>\n",
       "      <td>0.548328</td>\n",
       "      <td>0.098667</td>\n",
       "      <td>0.197181</td>\n",
       "      <td>1.059027</td>\n",
       "      <td>-1.022564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.739936</td>\n",
       "      <td>1.315138</td>\n",
       "      <td>-0.323457</td>\n",
       "      <td>0.197828</td>\n",
       "      <td>0.097751</td>\n",
       "      <td>1.401523</td>\n",
       "      <td>0.158434</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>-1.310970</td>\n",
       "      <td>-21.762801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.532921</td>\n",
       "      <td>-1.711970</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>-0.958374</td>\n",
       "      <td>-0.080812</td>\n",
       "      <td>-0.703859</td>\n",
       "      <td>-0.770784</td>\n",
       "      <td>-0.480845</td>\n",
       "      <td>0.703586</td>\n",
       "      <td>0.929145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473488</td>\n",
       "      <td>1.855246</td>\n",
       "      <td>1.415656</td>\n",
       "      <td>-0.302746</td>\n",
       "      <td>0.989679</td>\n",
       "      <td>0.585851</td>\n",
       "      <td>1.136388</td>\n",
       "      <td>0.671617</td>\n",
       "      <td>-0.974167</td>\n",
       "      <td>2.139453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.619685</td>\n",
       "      <td>0.572627</td>\n",
       "      <td>1.902618</td>\n",
       "      <td>-0.775664</td>\n",
       "      <td>-0.188090</td>\n",
       "      <td>-1.035748</td>\n",
       "      <td>1.177830</td>\n",
       "      <td>-2.305167</td>\n",
       "      <td>-2.263660</td>\n",
       "      <td>0.375020</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.303220</td>\n",
       "      <td>0.466751</td>\n",
       "      <td>0.161106</td>\n",
       "      <td>0.320032</td>\n",
       "      <td>2.079177</td>\n",
       "      <td>-0.907466</td>\n",
       "      <td>-0.192404</td>\n",
       "      <td>-1.212516</td>\n",
       "      <td>-0.080599</td>\n",
       "      <td>0.194017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.382732 -0.034242  1.096347 -0.234216 -0.347451 -0.581268 -1.632635   \n",
       "1  0.555963  0.892474 -0.422315  0.104714  0.228053  0.201480  0.540774   \n",
       "2  0.013240 -0.121945  0.339059 -0.589632 -0.895816  0.548328  0.098667   \n",
       "3 -1.532921 -1.711970  0.046135 -0.958374 -0.080812 -0.703859 -0.770784   \n",
       "4 -1.619685  0.572627  1.902618 -0.775664 -0.188090 -1.035748  1.177830   \n",
       "\n",
       "          7         8         9    ...           491       492       493  \\\n",
       "0 -1.567768 -1.179158  1.301428    ...      0.178793 -0.799422  0.240788   \n",
       "1 -1.818078 -0.049324  0.239034    ...     -0.740137 -0.565498  0.476031   \n",
       "2  0.197181  1.059027 -1.022564    ...     -0.739936  1.315138 -0.323457   \n",
       "3 -0.480845  0.703586  0.929145    ...      0.473488  1.855246  1.415656   \n",
       "4 -2.305167 -2.263660  0.375020    ...     -1.303220  0.466751  0.161106   \n",
       "\n",
       "        494       495       496       497       498       499          y  \n",
       "0  0.289121  0.412871 -0.198399  0.094192 -1.147611 -0.358114  -2.663126  \n",
       "1 -2.158069  1.318551 -0.239297 -0.246794 -1.079343 -0.114226  10.399650  \n",
       "2  0.197828  0.097751  1.401523  0.158434 -1.141901 -1.310970 -21.762801  \n",
       "3 -0.302746  0.989679  0.585851  1.136388  0.671617 -0.974167   2.139453  \n",
       "4  0.320032  2.079177 -0.907466 -0.192404 -1.212516 -0.080599   0.194017  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAC7CAYAAADrCt2SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC5IkqZVhQZIktTIsSJKkVoYFSZLU6v8ADUDKJtIoFNIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1169efa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "df = pd.read_csv('../data/hw2data.csv')\n",
    "df.head()\n",
    "\n",
    "#\n",
    "\n",
    "# Fill these in\n",
    "#alphas = []\n",
    "#train_errors=[]\n",
    "#test_errors=[]\n",
    "#alpha_optim=0\n",
    "\n",
    "\n",
    "\n",
    "#plt.semilogx(alphas, train_errors, label='Train')\n",
    "#plt.semilogx(alphas, test_errors, label='Test')\n",
    "#plt.vlines(alpha_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "#           linewidth=3, label='Optimum on test')\n",
    "#plt.legend(loc='lower left')\n",
    "#plt.ylim([0, 1.2])\n",
    "#plt.xlabel('Regularization parameter')\n",
    "#plt.ylabel('Performance')\n",
    "\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Plot the top coefficients based on this optimal paramter. Why do you think so many are zero? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Compute the $R^2$ with the optimal coefficient found above on 5 folds using cross_val_score and plot the\n",
    "results. Does the model work well on all random subsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Repeat e) but using cross validation. Use error bars on the features which are the standard deviation of the \n",
    "coefficiens obtained above. For this problem I\"ll walk you through the code. You just need to apply your optimal\n",
    "$\\alpha$ found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import preprocessing\n",
    "def run_cv_coeffs(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    coeffs=[]\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        coeffs.append(clf.coef_)\n",
    "    return coeffs\n",
    "\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = X.as_matrix().astype(np.float)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "coeffs=run_cv_coeffs(X_scaled,np.array(y),Lasso,alpha=alpha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_coeffs(coeffs):\n",
    "    coeffs_avgd = [(coeffs[0][i] + coeffs[1][i] + coeffs[2][i] + coeffs[3][i] + coeffs[4][i])/5 for i in range(0,len(X.columns))]\n",
    "    coeffs_std = [np.std([coeffs[0][i],coeffs[1][i],coeffs[2][i],coeffs[3][i],coeffs[4][i]]) for i in range(0,len(X.columns))]\n",
    "    return coeffs_avgd, coeffs_std\n",
    "coeffs_avg,coeffs_std=get_coeffs(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ef6d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCoeffs = pd.DataFrame({'type':X.columns.values, 'coef':coeffs_avg, 'std':coeffs_std})\n",
    "dfCoeffs = dfCoeffs[(dfCoeffs['coef']>1) |(dfCoeffs['coef']<-1) ]\n",
    "plt.figure(figsize=(15,15))\n",
    "dfCoeffs_sorted = dfCoeffs.sort(['coef'])[::-1]\n",
    "yerr_vals = dfCoeffs_sorted['std'].values\n",
    "dfCoeffs_sorted.plot(x='type',y='coef',kind='bar',yerr=yerr_vals,figsize=(15,15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
